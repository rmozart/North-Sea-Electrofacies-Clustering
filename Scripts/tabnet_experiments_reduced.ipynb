{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.6 64-bit ('phase1': conda)",
   "display_name": "Python 3.7.6 64-bit ('phase1': conda)",
   "metadata": {
    "interpreter": {
     "hash": "43575a95c5fa30f9c9f84c3d0129ba3f77c9622d889edcecf3dad2a10ecf7387"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../')\n",
    "import lasio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from collections import Counter\n",
    "pd.set_option('max_columns', None)\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../checkpoints/total_df.csv.gz', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "litho_data = df[pd.notnull(df['LITHOLOGY_GEOLINK'])].drop(columns=['WELL_NAME']) # not null dataframe (model training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "litho_data['LITHOLOGY_GEOLINK'] = litho_data['LITHOLOGY_GEOLINK'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "litho_data[\"Set\"] = np.random.choice([\"train_red\", \"rest\"], p =[.3, .7], size=(litho_data.shape[0],))\n",
    "\n",
    "train = litho_data[litho_data.Set == 'train_red']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(388380, 9) (1294715, 9)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape, litho_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = train.drop(columns=['LITHOLOGY_GEOLINK', 'Set'])\n",
    "\n",
    "Y = train['LITHOLOGY_GEOLINK']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state=42)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "### Training Dataset: ###  (248563, 7) (248563,)\n### Validation Dataset: ###  (62141, 7) (62141,)\n### Test Dataset: ###  (77676, 7) (77676,)\n"
     ]
    }
   ],
   "source": [
    "print('### Training Dataset: ### ', x_train.shape, y_train.shape)\n",
    "print('### Validation Dataset: ### ', x_val.shape, y_val.shape)\n",
    "print('### Test Dataset: ### ', x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Device used : cuda\n"
     ]
    }
   ],
   "source": [
    "clf = TabNetClassifier(optimizer_fn=torch.optim.Adam,\n",
    "                       optimizer_params=dict(lr=2e-2),\n",
    "                       scheduler_params={\"gamma\":0.5, \"step_size\":75},\n",
    "                       lambda_sparse=0.1,\n",
    "                       n_steps=8,\n",
    "                       n_shared=2,\n",
    "                       n_independent=5,\n",
    "                       n_a=32,\n",
    "                       momentum=0.1,\n",
    "                       scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "                       mask_type='entmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "std_scaler = StandardScaler()\n",
    "\n",
    "x_train = std_scaler.fit_transform(x_train)\n",
    "x_val = std_scaler.fit_transform(x_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_epochs = 1000\n",
    "\n",
    "clf.fit(\n",
    "    X_train=x_train, y_train=y_train,\n",
    "    eval_set=[(x_train, y_train), (x_val, y_val)],\n",
    "    eval_name=['train', 'valid'],\n",
    "    eval_metric=['balanced_accuracy'],\n",
    "    max_epochs=max_epochs , patience=150,\n",
    "    batch_size=2048,\n",
    "    num_workers=0,\n",
    "    weights=1,\n",
    "    drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(clf.history['train_balanced_accuracy'], label='Train Accuracy')\n",
    "plt.plot(clf.history['valid_balanced_accuracy'], label='Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(clf.history['loss'], label='Train Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(clf.history['lr'], label='Learning Rate Decay')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}