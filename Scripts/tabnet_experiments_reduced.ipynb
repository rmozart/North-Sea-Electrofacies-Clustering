{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.6 64-bit ('phase1': conda)",
   "display_name": "Python 3.7.6 64-bit ('phase1': conda)",
   "metadata": {
    "interpreter": {
     "hash": "43575a95c5fa30f9c9f84c3d0129ba3f77c9622d889edcecf3dad2a10ecf7387"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../')\n",
    "import lasio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from collections import Counter\n",
    "pd.set_option('max_columns', None)\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../checkpoints/total_df.csv.gz', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "litho_data = df[pd.notnull(df['LITHOLOGY_GEOLINK'])].drop(columns=['WELL_NAME']) # not null dataframe (model training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "litho_data['LITHOLOGY_GEOLINK'] = litho_data['LITHOLOGY_GEOLINK'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "litho_data[\"Set\"] = np.random.choice([\"train_red\", \"rest\"], p =[.3, .7], size=(litho_data.shape[0],))\n",
    "\n",
    "train = litho_data[litho_data.Set == 'train_red']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(388415, 9) (1294715, 9)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape, litho_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = train.drop(columns=['LITHOLOGY_GEOLINK', 'Set'])\n",
    "\n",
    "Y = train['LITHOLOGY_GEOLINK']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state=42)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "### Training Dataset: ###  (248585, 7) (248585,)\n### Validation Dataset: ###  (62147, 7) (62147,)\n### Test Dataset: ###  (77683, 7) (77683,)\n"
     ]
    }
   ],
   "source": [
    "print('### Training Dataset: ### ', x_train.shape, y_train.shape)\n",
    "print('### Validation Dataset: ### ', x_val.shape, y_val.shape)\n",
    "print('### Test Dataset: ### ', x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Device used : cuda\n"
     ]
    }
   ],
   "source": [
    "clf = TabNetClassifier(               optimizer_fn=torch.optim.Adam,\n",
    "                       optimizer_params=dict(lr=2e-2),\n",
    "                       scheduler_params={\"step_size\":50, # how to use learning rate scheduler\n",
    "                                         \"gamma\":0.9},\n",
    "                       scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "                       mask_type='entmax' # \"sparsemax\"\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 1000\n",
    "\n",
    "clf.fit(\n",
    "    X_train=x_train.values, y_train=y_train,\n",
    "    eval_set=[(x_train.values, y_train), (x_val.values, y_val)],\n",
    "    eval_name=['train', 'valid'],\n",
    "    eval_metric=['balanced_accuracy'],\n",
    "    max_epochs=max_epochs , patience=20,\n",
    "    batch_size=1024,\n",
    "    num_workers=0,\n",
    "    weights=1,\n",
    "    drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}